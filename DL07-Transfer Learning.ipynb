{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Transfer Learning\n",
    "\n",
    "\n",
    "The goal of this exercise is to learn how to use pre-trained networks in transfer learning tasks.\n",
    "We will make use of networks trained on ImageNet, and apply them to related problems, i.e., the classification of $10$ objects not contained in ImageNet."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For this exercise we use the  [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset that can be downloaded from the official website [here]({https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz}).\n",
    "The dataset contains $60000$ color images of pixels size $32\\times 32$ in $10$ classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck, with $6000$ images per class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Transformation\n",
    "\n",
    "We need to instantiate a proper `torchvision.transform` instance to create the same input structure as used for training our network.\n",
    "We need to combine 4 transforms, which can be compiled from the PyTorch website: https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "1. We need to resize the image such that the shorter side has size 256.\n",
    "2. We need to take the center crop of size $224\\times224$ from the image.\n",
    "3. We need to convert the image into a tensor (including pixel values scaling)\n",
    "4. We need to normalize the pixel values with mean $(0.485, 0.456, 0.406)$ and standard deviation $(0.229, 0.224, 0.225)$.\n",
    "\n",
    "Since we will use networks pre-trained on ImageNet, we need to perform the exact same transform as used for ImageNet testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "imagenet_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Dataset Loading\n",
    "\n",
    "We here use the [torchvision.datasets.CIFAR10](https://pytorch.org/vision/0.12/generated/torchvision.datasets.CIFAR10.html) dataset interface for processing images. \n",
    "You can use the `train` argument or flag to distinguish between training and test set.\n",
    "\n",
    "This task consists of two parts:\n",
    "\n",
    "1. Create two datasets, one for the training set, one for the test set. Use the transform defined above.\n",
    "2. Once the datasets are created, create two data loaders, one for training set, one for test set. Use a proper value of the batch-size $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(\n",
    "  root = \"./CIFAR-10\", train=True, transform=imagenet_transform, download=True\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "  root = \"./CIFAR-10\", train=False, transform=imagenet_transform, download=True\n",
    ")\n",
    "print(len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 256\n",
    "trainloader = torch.utils.data.DataLoader(trainset, shuffle=True, batch_size = B)\n",
    "testloader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size = B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Data Size and Types\n",
    "\n",
    "We check that all input images are `torch.tensors` of size $3\\times224\\times224$ and of type `torch.float` and that all labels are of type `int`.\n",
    "\n",
    "Note: the sanity check is only performed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x, t in testset:\n",
    "#   assert isinstance(x, torch.Tensor)\n",
    "#   assert isinstance(t, int)\n",
    "#   assert x.shape==(3,224,224)\n",
    "#   assert x.dtype==torch.float"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Feature Extraction\n",
    "\n",
    "We will use a pre-trained network available in `PyTorch`. \n",
    "Particularly, we will use a ResNet-50 architecture, but other architectures can also be tested. \n",
    "Fortunately, PyTorch provides simple interfaces to obtain pre-trained models, e.g., using the `torchvision.models.resnet50` interface function.\n",
    "\n",
    "In order to use the networks in a different dataset, we need to change their outputs. \n",
    "There are several possibilities on how to achieve that, and you have the freedom to choose. \n",
    "\n",
    "For your reference, the implementation of the `forward` function of ResNet networks (including ResNet-50) can be found here: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L266\n",
    "\n",
    "You can also check if other networks perform better, for example, deeper ResNet topologies.\n",
    "Be aware that the strategy to replace the last fully-connected layer might not work in other network topologies, only in residual networks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Pre-trained Network Instantiation\n",
    "\n",
    "Instantiate two pre-trained networks of type ResNet-50.\n",
    "\n",
    "1. Freeze the feature layers of the first network.\n",
    "\n",
    "Note: Make use the `old TorchVision Interface` to load your pre-trained network. Here is the link: https://pytorch.org/vision/0.12/models.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the first pre-trained resnet 50 network\n",
    "network_1 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "# print(network_1)\n",
    "# Make sure to freeze all the layers of the network.\n",
    "for param in network_1.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# instantiate the second pre-trained resnet 50 network (optinally)\n",
    "network_2 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Network Implementation\n",
    "\n",
    "We want to modify the network such that we extract the logits for the 10 classes from CIFAR-10 from the last fully-connected layer of the network.\n",
    "\n",
    "Implement a function that:\n",
    "1. Replaces the current last linear layer of the pre-trained network with a new linear layer that has $O$ units ($O$ represents the number of classes in our dataset).\n",
    "2. Initialize the weights of the new linear layer using Xavier's method **(Optional)**.\n",
    "\n",
    "Note: Use `torch.nn.init.xavier_uniform_` function to initialize the weights of the new linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_last_layer(network, O=10):\n",
    "  # replace the last linear layer with the new layer\n",
    "  network.fc = torch.nn.Linear(network.fc.in_features, O)\n",
    "  # initialize the weights of the new linear layer\n",
    "  torch.nn.init.xavier_uniform_(network.fc.weight)\n",
    "  return network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Last layer dimensions\n",
    "\n",
    "This test ensures that the function return a network having the correct number of input and output units in the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = 10\n",
    "for network in (network_1, network_2):\n",
    "    new_model = replace_last_layer(network, O=O)\n",
    "    assert new_model.fc.out_features == O\n",
    "    assert new_model.fc.in_features == 2048"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Training\n",
    "Implement a function that takes all necessary parameters to run a training on a given dataset. \n",
    "Select the optimizer to be `torch.optim.SGD` and `torch.nn.CrossEntropyLoss` as the loss function. \n",
    "The test set will be used as the validation set."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Training and Evaluation Loop\n",
    "\n",
    "Implement a training loop over a specific number of epochs (10) with a learning rate of $\\eta=0.001$ and momentum of $\\mu = 0.9$. \n",
    "Make sure that you train on the training data only, and `not` on the validation data.\n",
    "In each loop, compute and print the training loss, training accuracy, validation loss and validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(model, epochs=10, eta=1e-3, miu=0.9):\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=eta, momentum=miu)\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    train_loss, train_acc = [], []\n",
    "    test_loss, test_acc = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss_train, acc_train = 0, 0\n",
    "        # training process\n",
    "        for x,t in trainloader:\n",
    "            z = model(x.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            J = loss(z, t.to(device))\n",
    "            loss_train += J.item()\n",
    "            acc_train += torch.sum(torch.argmax(z, dim=1) == t.to(device)).item()\n",
    "            J.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_loss.append(loss_train / len(trainset))\n",
    "        train_acc.append(acc_train / len(trainset))\n",
    "        \n",
    "        # testing process\n",
    "        with torch.no_grad():\n",
    "            loss_test, acc_test = 0, 0\n",
    "            for x,t in testloader:\n",
    "                z = model(x.to(device))\n",
    "                # compute validation loss\n",
    "                J_test = loss(z, t.to(device))\n",
    "                loss_test += J_test.item()\n",
    "                # compute validation accuracy\n",
    "                acc_test += torch.sum(torch.argmax(z, dim=1) == t).item()\n",
    "\n",
    "            test_loss.append(loss_test / len(testset))\n",
    "            test_acc.append(acc_test / len(testset))\n",
    "\n",
    "        # print accuracies and losses for current epoch\n",
    "        print(f\"Epoch:{epoch}, \\\n",
    "                Train_Loss:{train_loss[-1]},Train_Acc:{train_acc[-1]} | \\\n",
    "                Test_Loss:{test_loss[-1]},Test_Acc:{test_acc[-1]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Network Fine-Tuning with Frozen Layers\n",
    "\n",
    "Create a network that has feature layers frozen with $10$ output units. \n",
    "Fine-tune the created network on our CIFAR-10 data using the previous function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=10, bias=True)\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\UZH_Code\\Deep Learning\\DL-Assignment07.ipynb Cell 21\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UZH_Code/Deep%20Learning/DL-Assignment07.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m network_with_frozen_layers \u001b[39m=\u001b[39m replace_last_layer(network_1, \u001b[39m10\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/UZH_Code/Deep%20Learning/DL-Assignment07.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(network_with_frozen_layers\u001b[39m.\u001b[39mfc)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/UZH_Code/Deep%20Learning/DL-Assignment07.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_eval(network_with_frozen_layers)\n",
      "\u001b[1;32md:\\UZH_Code\\Deep Learning\\DL-Assignment07.ipynb Cell 21\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UZH_Code/Deep%20Learning/DL-Assignment07.ipynb#X26sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m z \u001b[39m=\u001b[39m model(x\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UZH_Code/Deep%20Learning/DL-Assignment07.ipynb#X26sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# compute validation loss\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/UZH_Code/Deep%20Learning/DL-Assignment07.ipynb#X26sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m J_test \u001b[39m=\u001b[39m loss(z, t)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UZH_Code/Deep%20Learning/DL-Assignment07.ipynb#X26sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m loss_test \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m J_test\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/UZH_Code/Deep%20Learning/DL-Assignment07.ipynb#X26sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# compute validation accuracy\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\functional.py:3029\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3027\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3029\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "network_with_frozen_layers = replace_last_layer(network_1, 10)\n",
    "print(network_with_frozen_layers.fc)\n",
    "train_eval(network_with_frozen_layers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 (Optional): Network Fine-Tuning without Frozen Layers \n",
    "\n",
    "Create a network from the second pre-trained network with $10$ output units. \n",
    "Fine-tune the created network on our CIFAR-10.\n",
    "\n",
    "Note:\n",
    "\n",
    "  * The fine-tuning of the network can take a long time when the layers are not frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_normal = ...\n",
    "train_eval(...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Finally, we want to plot the confusion matrix of the test set.\n",
    "For this, we need to compute the predictions for all of our test samples, and the list of target values.\n",
    "Finally, we can make use of the `sklearn.metrics.confusion_matrix` to compute the confusion matrix.\n",
    "You can utilize `sklearn.metrics.ConfusionMatrixDisplay` for displaying the confusion matrix, or `pyplot.imshow` and adding the according labels.\n",
    "\n",
    "Note:\n",
    "\n",
    "  * The documentation for the confusion matrix can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "  * The interface and an example for the `ConfusionMatrixDisplay` can be found here: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Confusion Matrix Plotting\n",
    "\n",
    "Plot the confusion matrix for the fine-tuned network with frozen layers.\n",
    "Optionally, also plot the confusion matrix for the second fine-tuned network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "network_with_frozen_layers.eval()\n",
    "# compute predictions and collect targets\n",
    "predictions = []\n",
    "targets = []\n",
    "with torch.no_grad():\n",
    "    for images, targets in testloader:\n",
    "        outputs = network_with_frozen_layers(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.append(predicted.cpu().numpy())\n",
    "        targets.append(targets.cpu().numpy())\n",
    "\n",
    "# compute confusion matrix\n",
    "matrix = confusion_matrix(targets, predictions)\n",
    "\n",
    "# plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=list(range(O)))\n",
    "disp.plot()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
